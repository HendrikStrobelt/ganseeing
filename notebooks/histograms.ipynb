{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['lines.linewidth'] = 0.25\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.linewidth'] = 0.25\n",
    "\n",
    "import torch, numpy, os\n",
    "from scipy.io import loadmat\n",
    "from IPython.display import display\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load up the training data set for a GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seeing import fsd\n",
    "cachedir = 'results/fsd/cache'\n",
    "true_churches = 'datasets/lsun/church_outdoor_train'\n",
    "pgan_churches = 'results/imagesample/church/size_10000'\n",
    "\n",
    "true_churches_tally, pgan_churches_tally = [\n",
    "    fsd.cached_tally_directory(d, size=10000, cachedir=cachedir, seed=1)\n",
    "    for d in [true_churches, pgan_churches]]\n",
    "\n",
    "\n",
    "true_bedrooms = 'datasets/lsun/bedroom_train'\n",
    "pgan_bedrooms = 'results/imagesample/bedroom/size_10000'\n",
    "\n",
    "true_bedrooms_tally, pgan_bedrooms_tally = [\n",
    "    fsd.cached_tally_directory(d, size=10000, cachedir=cachedir, seed=1)\n",
    "    for d in [true_bedrooms, pgan_bedrooms]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seeing import segmenter\n",
    "\n",
    "def print_stats(result):\n",
    "    upp = segmenter.UnifiedParsingSegmenter()\n",
    "    labelnames, catnames = upp.get_label_and_category_names()\n",
    "    for label in (-result).sort(0)[1]:\n",
    "        if label == 0 or labelnames[label][1] == 'material':\n",
    "            continue\n",
    "        if result[label] == 0:\n",
    "            break\n",
    "        print(label.item(), labelnames[label][0], result[label].item())\n",
    "\n",
    "# print_stats(gresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_diff(tresult, gresult):\n",
    "    upp = segmenter.UnifiedParsingSegmenter()\n",
    "    labelnames, catnames = upp.get_label_and_category_names()\n",
    "    for label in (-tresult).sort(0)[1]:\n",
    "        if label == 0 or labelnames[label][1] == 'material':\n",
    "            continue\n",
    "        if tresult[label] == 0:\n",
    "            break\n",
    "        print(label.item(), labelnames[label][0], tresult[label].item(),\n",
    "             (gresult[label] - tresult[label]).item(),\n",
    "             ((gresult[label] - tresult[label]).float() / tresult[label]).item())\n",
    "# print_diff(tresult, gresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_diff(ttally, gtally, title='Objects in Generated vs Training scenes',\n",
    "              count=30, labelleft=True, dpi=100, legend=False):\n",
    "    tresult, gresult = [t.mean(0) for t in [ttally, gtally]]\n",
    "    upp = segmenter.UnifiedParsingSegmenter()\n",
    "    labelnames, catnames = upp.get_label_and_category_names()\n",
    "    x = []\n",
    "    labels = []\n",
    "    gen_amount = []\n",
    "    change_frac = []\n",
    "    true_amount = []\n",
    "    for label in numpy.argsort(-tresult):\n",
    "        if label == 0 or labelnames[label][1] == 'material':\n",
    "            continue\n",
    "        if tresult[label] == 0:\n",
    "            break\n",
    "        x.append(len(x))\n",
    "        labels.append(labelnames[label][0].split()[0])\n",
    "        true_amount.append(tresult[label].item())\n",
    "        gen_amount.append(gresult[label].item())\n",
    "        change_frac.append((float(gresult[label] - tresult[label])\n",
    "                            / tresult[label]))\n",
    "        if len(x) >= count:\n",
    "            break\n",
    "    f, (a1, a0) = plt.subplots(2, 1, gridspec_kw = {'height_ratios':[1.2, 2]}, dpi=dpi)\n",
    "    \n",
    "    a0.bar(x, change_frac, label='relative delta', color='cornflowerblue')\n",
    "    a0.set_xticks(x)\n",
    "    a0.set_xticklabels(labels, rotation='vertical')\n",
    "    a0.set_ylabel('relative delta\\n(gen - train) / train')\n",
    "    a0.set_ylim([-1, 1.1])\n",
    "    a0.grid(axis='y', antialiased=False, alpha=0.25)\n",
    "    if legend:\n",
    "        a0.legend(loc=2)\n",
    "    #a0.text(1 if labelleft else 30, 0.9, 'relative delta',\n",
    "    #       horizontalalignment='left' if labelleft else 'right', verticalalignment='top',\n",
    "    #       )\n",
    "    prev_high = None\n",
    "    for ix, cf in enumerate(change_frac):\n",
    "        if cf > 1.15:\n",
    "            if prev_high == (ix - 1):\n",
    "                offset = 0.1\n",
    "            else:\n",
    "                offset = 0.0\n",
    "                prev_high = ix\n",
    "            a0.text(ix, 1.15 + offset, '%.1f' % cf, horizontalalignment='center', size=6)\n",
    "            \n",
    "    a1.bar(x, true_amount, label='training', color='cornflowerblue')\n",
    "    a1.plot(x, gen_amount, linewidth=3, color='red', label='generated')\n",
    "    a1.set_yscale('log')\n",
    "    a1.set_ylim(1e-2, 50)\n",
    "    a1.set_yticks([1e-2, 1e-1, 1e+0, 1e+1])\n",
    "\n",
    "    a1.set_ylabel('mean area\\nlog scale')\n",
    "    # a1.text(30, numpy.max(true_amount), 'mean area in training data, log scale',\n",
    "    #       horizontalalignment='right', verticalalignment='top',\n",
    "    #       )\n",
    "    # a1.set_title(title)\n",
    "    if legend:\n",
    "        a1.legend()\n",
    "\n",
    "    # plt.subplots_adjust(bottom=0.10)\n",
    "    a1.set_xticks([])\n",
    "    # Pad margins so that markers don't get clipped by the axes\n",
    "    # plt.margins(0.2)\n",
    "    f.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seeing import frechet_distance\n",
    "\n",
    "print(frechet_distance.sample_frechet_distance(true_churches_tally * 100, pgan_churches_tally * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "plot_diff(true_churches_tally*100, pgan_churches_tally*100, title='', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_diff(true_bedrooms_tally*100, pgan_bedrooms_tally*100, title='', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mname in arch_tally_100.keys():\n",
    "    print(mname, frechet_distance.sample_frechet_distance(bedroom_result_100[0], arch_tally_100[mname]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.argmax(arch_tally_100['minibatch-stddev'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablated_bedroom_stats = tally_ablated_model(SETTINGS.bedroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'wgangp' in arch_tally_100:\n",
    "    plot_diff(bedroom_result_100[0][:10000], arch_tally_100['wgangp'][:10000],\n",
    "          title='Objects in wgangp Generated vs Training Bedrooms', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'proggan' in arch_tally_100:\n",
    "    plot_diff(bedroom_result_100[0][:10000], arch_tally_100['proggan'][:10000],\n",
    "          title='Objects in with progressive training Generated vs Training Bedrooms', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'minibatch-stddev' in arch_tally_100:\n",
    "    plot_diff(bedroom_result_100[0][:10000], arch_tally_100['minibatch-stddev'][:10000],\n",
    "          title='Objects in with progressive training Generated vs Training Bedrooms', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'stylegan' in arch_tally_100:\n",
    "    plot_diff(bedroom_result_100[0][:10000], arch_tally_100['stylegan'][:10000],\n",
    "          title='Objects in with stylegan Generated vs Training Bedrooms', dpi=500, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_diff(*bedroom_result_100,\n",
    "          title='Objects in Generated vs Training Bedrooms', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_diff(bedroom_result_100[0][:10000], inverted_tally,\n",
    "          title='Objects in inverted images Generated vs Training Bedrooms', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_diff(bedroom_result_100[0][:10000], net_inverted_tally,\n",
    "          title='Objects in inverted images Generated vs Training Bedrooms', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_tally_100['stylegan'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frechet_distance.sample_frechet_distance(bedroom_result_100[0], bedroom_result_100[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedroom_result[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedroom_result[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_diff(*bedroom_result_100,\n",
    "          title='Objects in Generated vs Training Bedrooms', dpi=500, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_diff(*church_result_100,\n",
    "         title='Objects in Generated vs Training Churches', dpi=500, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_maximizing_labels(setting):\n",
    "    dataset = load_dataset(setting, 'train')\n",
    "    loader = DataLoader(dataset,\n",
    "                        # sampler=FixedRandomSubsetSampler(dataset, end=1000),\n",
    "                        sampler=FixedSubsetSampler(range(1000)),\n",
    "                        batch_size=10, pin_memory=True)\n",
    "    upp = segmenter.UnifiedParsingSegmenter()\n",
    "    best_index = torch.zeros(NUM_OBJECTS, dtype=torch.long)\n",
    "    best = torch.zeros(NUM_OBJECTS, dtype=torch.long).cuda()\n",
    "    with torch.no_grad():\n",
    "        batch_index = 0\n",
    "        for [batch] in progress(loader):\n",
    "            seg_result = upp.segment_batch(batch.cuda())\n",
    "            for i in range(len(batch)):\n",
    "                result = seg_result[i,0].view(-1).bincount(minlength=NUM_OBJECTS)\n",
    "                records = (result > best).nonzero()\n",
    "                for label in records:\n",
    "                    best_index[label] = batch_index + i\n",
    "                    best[label] = result[label]\n",
    "            batch_index += len(batch)\n",
    "    return best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedroom_examples = images_maximizing_labels(SETTINGS.bedroom)\n",
    "church_examples = images_maximizing_labels(SETTINGS.church)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i, (n, c) in enumerate(labelnames) if n == 'car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "church_examples[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = parallelfolder.ParallelImageFolders(\n",
    "            ['/data/vision/torralba/scratch2/davidbau/newdissect/imagesample/compare_arch/size_10000/minibatch-stddev/baseline/'],\n",
    "            transform=transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(256),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classnum = 2\n",
    "modelname = 'minibatch-stddev'\n",
    "\n",
    "def show_top_seg_examples(modelname, classnum):\n",
    "    upp = segmenter.UnifiedParsingSegmenter()\n",
    "    print(upp.get_label_and_category_names()[0][classnum][0])\n",
    "    dataset = load_arch_dataset(modelname)\n",
    "    top_10_images = [dataset.images[i][0]\n",
    "                     for i in numpy.argsort(arch_tally_100[modelname][:,classnum])[-10:][::-1]]\n",
    "    for filename in top_10_images:\n",
    "        im = Image.open(filename)\n",
    "        display(im.resize((256, 256)))\n",
    "        img = ((transforms.functional.to_tensor(im.resize([256,256])) - 0.5) * 2)[None,:,:,:]\n",
    "        seg_result = upp.raw_seg_prediction(img.cuda())\n",
    "        obj_seg = seg_result[0]['object']\n",
    "        obj_labels = obj_seg.max(1)[1].cpu().numpy()\n",
    "        # Recolor some labels\n",
    "        # obj_labels[obj_labels == 5] = 12\n",
    "        # obj_labels[obj_labels == 4] = 5\n",
    "        sv = segviz.segment_visualization(recolored(obj_labels), (256, 256))\n",
    "        display(Image.fromarray(sv))\n",
    "        obj2 = obj_labels.copy()\n",
    "        obj2[obj2 != classnum] = 0\n",
    "        sv2 = segviz.segment_visualization(recolored(obj2), (256, 256))\n",
    "        display(Image.fromarray(sv2))\n",
    "\n",
    "def recolored(labels):\n",
    "    print(labels.shape)\n",
    "    bldg = (labels == 5)\n",
    "    tree = (labels == 4)\n",
    "    chair = (labels == 12)\n",
    "    labels_rc = labels.copy()\n",
    "    labels_rc[bldg] = 12\n",
    "    labels_rc[tree] = 5\n",
    "    labels_rc[chair] = 4\n",
    "    return labels_rc\n",
    "\n",
    "show_top_seg_examples('stylegan', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.images[8371]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from netdissect import segmenter\n",
    "from netdissect import segviz\n",
    "from torchvision import transforms\n",
    "import numpy\n",
    "\n",
    "# filename = '/data/vision/torralba/scratch2/davidbau/encoder/results/bedroom/optimize_residuals/cases/opt_n_136/images/136_a_3000.png'\n",
    "filename = '/data/vision/torralba/scratch2/davidbau/encoder/results/bedroom/optimize_residuals/cases/opt_n_136/images/136_target.png'\n",
    "# filename = '/data/vision/torralba/scratch2/davidbau/encoder/results/bedroom/optimize_residuals/summary_s/316_target.png'\n",
    "# filename = '/data/vision/torralba/scratch2/davidbau/encoder/results/bedroom/optimize_residuals/summary_s/316_a_3000.png'\n",
    "# filename = '/data/vision/torralba/scratch2/davidbau/newdissect/imagesample/compare_arch/size_10000/minibatch-stddev/baseline/image_1647.png'\n",
    "# filename = '/data/vision/torralba/scratch2/davidbau/encoder/results/church/optimize_residuals/summary_n/883_target.png'\n",
    "# filename = '/data/vision/torralba/scratch2/davidbau/encoder/results/diningroom/optimize_residuals/cases/opt_n_81/images/81_target.png'\n",
    "# filename = '/data/vision/torralba/scratch2/davidbau/encoder/results/diningroom/optimize_residuals/cases/opt_n_81/images/81_a_3000.png'\n",
    "# filename = '/data/vision/torralba/scratch2/davidbau/encoder/results/diningroom/optimize_residuals/cases/opt_n_124/images/124_target.png'\n",
    "# filename = '/data/vision/torralba/scratch2/davidbau/encoder/results/diningroom/optimize_residuals/cases/opt_n_124/images/124_a_3000.png'\n",
    "# filename = '/data/vision/torralba/scratch2/davidbau/encoder/results/livingroom/optimize_residuals/cases/opt_n_5/images/5_a_3000.png'\n",
    "# filename = '/data/vision/torralba/scratch2/davidbau/encoder/results/livingroom/optimize_residuals/cases/opt_n_5/images/5_target.png'\n",
    "# filename = '/data/vision/torralba/scratch2/davidbau/encoder/results/livingroom/optimize_residuals/cases/opt_n_34/images/34_a_3000.png'\n",
    "# filename = '/data/vision/torralba/scratch2/davidbau/encoder/results/livingroom/optimize_residuals/cases/opt_n_34/images/34_target.png'\n",
    "# filename = '/data/vision/torralba/scratch2/davidbau/encoder/results/kitchen/optimize_residuals/cases/opt_i_8/images/8_a_3000.png'\n",
    "# filename = '/data/vision/torralba/scratch2/davidbau/encoder/results/kitchen/optimize_residuals/cases/opt_i_8/images/8_target.png'\n",
    "#filename = '/data/vision/torralba/scratch2/davidbau/encoder/results/kitchen/optimize_residuals/cases/opt_i_24/images/24_a_3000.png'\n",
    "filename = '/data/vision/torralba/scratch2/davidbau/encoder/results/kitchen/optimize_residuals/cases/opt_i_24/images/24_target.png'\n",
    "\n",
    "im = Image.open(filename)\n",
    "display(im.resize((256, 256)))\n",
    "img = ((transforms.functional.to_tensor(im.resize([256,256])) - 0.5) * 2)[None,:,:,:]\n",
    "\n",
    "with torch.no_grad():\n",
    "    upp = segmenter.UnifiedParsingSegmenter()\n",
    "    seg_result = upp.raw_seg_prediction(img.cuda())\n",
    "    obj_seg = seg_result[0]['object']\n",
    "\n",
    "obj_labels = recolored(obj_seg.max(1)[1].cpu().numpy())\n",
    "# Recolor some labels\n",
    "# obj_labels[obj_labels == 5] = 12\n",
    "# obj_labels[obj_labels == 4] = 5\n",
    "sv = segviz.segment_visualization(obj_labels, (256, 256))\n",
    "display(Image.fromarray(sv))\n",
    "\n",
    "for label in numpy.argsort(numpy.bincount(obj_labels.flatten()))[-15:][::-1]:\n",
    "    obj2 = obj_labels.copy()\n",
    "    obj2[obj2 != label] = 0\n",
    "    sv2 = segviz.segment_visualization(obj2, (256, 256))\n",
    "    display(Image.fromarray(sv2))\n",
    "    print(upp.get_label_and_category_names()[0]['label'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upp.get_label_and_category_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.argmax(arch_tally_100['minibatch-stddev'][:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.bincount(obj_labels.flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}